## Unveiling MITRE ATT&CK Techniques using Machine Learning Models for Command Classification

> Title is generated by ChatGPT

## Member
- 蘇俊銘, S11120013, NTHU IIS

## Intro

在現今的網路環境中, 攻擊手法層出不窮, 光有紀錄在 MITRE ATT&CK 框架的手法, 就有超過 [411](https://attack.mitre.org/techniques/enterprise/) 個了, 更不用說沒被記錄上去的手法以及尚未被開採的 0-day

基於這個問題, 我想提出一種方法, 可以將指令分類成 MITRE ATT&CK 中的 Tactics, 這個分類可以幫助分析環境整體安全性及潛在的危險

若環境已經遭受攻擊, 可以從中分析常遭受到何種 Tactics 攻擊或是對哪個 Tactics 的防禦力較弱, 並針對痛點來進行加強性的修補, 藉此來增進環境整體的安全性

除了可以增進安全性外, 也可以根據分類的結果來判斷攻擊者是否使用 0-day 進行攻擊
- 可行的原因是因為若發現分析的結果是靠後半部的 Tactics (e.g., Collection, Exfiltration) 較多, 若模型本身的表現不錯, 能偵測到大部分已知的攻擊, 那就可以推斷出可能是遭受沒有被紀錄過的攻擊

又或者是可以透過分析來判斷目前攻擊者進行到哪個 Tactics 

## Dataset

- https://github.com/center-for-threat-informed-defense/adversary_emulation_library
	- `[APT_Group]/Emulation_Plan/yaml/[APT_Group].yaml` 中的 `command`
- https://github.com/trellix-enterprise/ac3-threat-sightings
	- `sightings/Sightings_[APT, Technique, C2, Ransomware].yml` 中的 `cmdLine`
- https://github.com/redcanaryco/atomic-red-team
	- `atomics/[TID]/[TID].yaml` 中的 `command`


## 實際流程
### Pre-Preprocessing
1. 先將 dataset 中的資料清理成只包含 "`Tactics`", "`command`"
2. 將 `Tactics` 做 Label Encoder
3. 用 nltk 刪除一些 stopwords,  但 performace 沒有差太多, 故省略此步驟
4. 使用 `TfidfVectorizer`, `Word2Vec` 之類的 Word Embedding 將 `command` 轉換成後續 model 可使用的格式
	- `TfidfVectorizer`
		- analyzer 使用 word, 因為 command 需要一個 word 一個 word 做分析
	- `Word2Vec`
		- 在訓練模型的時候發現如果直接將 command 透過 `Word2Vec` 轉換成 vector, 由於後續需要 fit 進模型中, 因此會對轉換完的 vector 進行 padding, 但由於字詞太多, 因此 padding 會有太多 0, 因此透過犧牲一些太長的指令, 來換取較為

### Model
- TfidfVectorizer + SVM 
	- Train Accuracy: 82.85 % 
	- Test Accuracy: 59.68 %

- TfidfVectorizer + RandomForest  
	- Train Accuracy: 68.94 %
	- Test Accuracy: 46.77 %

- Word2Vec + SVM
	- 沒對字串做限制
		- Test Accuracy: 31.45 %
	- 有對字串做限制
		- Test Accuracy: 34.89 %

- Word2Vec + CNN
	- Convolutional Layers:
		- Conv1D Layer: Apply 1D convolution to capture local patterns in the embedded vectors.
		- Filters: 128
		- Kernel Size: 3
		- Activation: ReLU
		- GlobalMaxPooling1D Layer: Perform global max pooling to extract the most important features from the convolutional outputs.
	- Dense Layers:
		- Dense Layer: Apply fully connected layer with 14 units and ReLU activation.

	- Result
		- 沒對字串做限制
			- Test Accuracy: 31.45 %
		- 有對字串做限制
			- Test Accuracy: 34.89 %

- Word2Vec + AutoEncoder
	- Encoder Layers:
		- Dense Layer: 256 units with ReLU activation
		- Dense Layer: 128 units with ReLU activation
		- Dense Layer: 64 units with ReLU activation
	- Decoder Layers:
		- Dense Layer: 128 units with ReLU activation
		- Dense Layer: 256 units with ReLU activation
		- Dense Layer: 14 units with sigmoid activation (output layer)
	- Model Compilation:
		- Optimizer: Adam
		- Loss Function: Binary Crossentropy
   
	- Result
		- 沒對字串做限制
			- Test Accuracy: 31.45 %
		- 有對字串做限制
			- Test Accuracy: 34.89 %

## Conclusion & Discussion
- 可以從圖表看出結果除了 Tfidf+SVM 及 Tfidf+Random Forest 的準確度差強人意之外, 其餘模型的表現都十分糟糕, 可能的原因有以下
	1. Word Embedding 的方式
		- 雖然 TfidfVectorizer 可能有 overfitting 的狀況, 但其 test set 的 accuracy 還是大於 Word2Vec 將近 20 %
		- 而會造成這件事的原因是, 因為指令有許多文字, 在對這些文字做 Word2Vec 時, 因為每個指令的長度都不同, 因此在 fit 進模型前需要 padding, 這會造成很多的 0
		- 若能成功解決這個問題, Word2Vec 能讓字詞之間有上下文的關係, 這個特性應該是會蠻適合指令的, 但找不到好方法, 因此 TfidfVectorizer 的 performace 會比 Word2Vec 好上不少
	2. Dataset 太少
		- 網路上和攻擊手法相關並且有上 Tactics tag 的 Dataset 很少, 並且格式都很不統一
	   
- 觀察一下資料集以及其餘 NLP 相關的文章可以歸納出一些以後可以加強的地方
	1. 增加更多 feature, e.g., LOLBAS, Virustotal 檢測 等
	2. 改良 word embedding 的方式, 或使用不同的演算法
	3. 找更多 data 